Author: Chen Zhang, with CIMS NYU
Email:  chen.zhang@nyu.edu

This is a minimum search engine in response for Programming Assignment 1 
of CSCI-GA.2580-001 Web Search Engine, taught by Prof. Ernest Davis with 
New York University. 

Requirement: 
    - Python 2.7     ( Preferably. Some python standard libaraies are imported 
            in 2.7 fashion. If you insist on 3.x, feel free to mordify the 
            import part in ./source/crawler.py)
    - Django         ( The website is depolyed using Django. )
    - Pylucene 3.x   ( Preferably. The website is developed using 3.5 and 3.6. 
            In 6.2, the function and classes are imported in a very different 
            fashion. If you insist on 6.2, feel free to modify .py files in 
            ./lucene. )
    - BeautifulSoup4 ( The html parser used in this project. )

Instructions:
    Simply run 
        >> python manage.py runserver
    You can than access the website from 
        localhost:8000
    The instructions on the should be straight forward. 

Directory:
    - ./source
        - Build.py
            The BuildSearchEngine(start,number,domain). It uses ./crawler.py 
            and ../lucene/IndexFiles.py to download pages as instructed and 
            index the text ( and javascipt code occasionally ) in the body 
            of downloaded pages. 
        - crawler.py
            It is built based on the crawler in 
            http://www.netinstructions.com/how-to-make-a-web-crawler-in-under-50-lines-of-python-code/
            A few features are added to the basic crawler. 
            Namely, 
                1. Robot Exclusive Standard. 
                    It is implemented using the robotparser from the Python 
                    Standard Library. 
                2. URL normalization. 
                    There are two kinds of URL normalization in the crawler. 
                    One is for visiting the website with the right protocal. 
                    The other is for truncating URL ( removing the "http://" 
                    or "https://" in the front, and "/" or "/index.html" in 
                    the end. ) so that websites with acctually the same URL 
                    will not be visited again. 
                3. Cache and index.
                    The text in the body of websites ( including javascript code )
                    is cached with the help of BeatifulSoup4, and indexed using 
                    Pylucene. 
    - ./lucene
        - ./index
            This is the index file generated by Pylucene. 
        - IndexFiles.py
            It is basically the sample file with the Pylucene package. 
        - SearchFiles.py
            It is basically the sample file with the Pylucene package. 
    - cache
        Generated by crawler. The text of the cached pages are stored here. 
    - *
        Django related files. 
